\documentclass[10pt]{beamer}

\usetheme[progressbar=frametitle]{metropolis}
\usepackage{appendixnumberbeamer}
\usepackage{amsmath,amsfonts,amssymb,amsthm,xcolor}
\usepackage{booktabs}
\usepackage[scale=2]{ccicons}

\usepackage{pgfplots}
\usepgfplotslibrary{dateplot}

\usepackage{xspace}
\newcommand{\themename}{\textbf{\textsc{metropolis}}\xspace}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\title{Adversarial Machine Learning}
\subtitle{A comprehensive overview}
% \date{\today}
\date{}
\author{Abhinav Venkataraman}
\institute{Samsung SDS Research America}
% \titlegraphic{\hfill\includegraphics[height=1.5cm]{logo.pdf}}

\begin{document}

\maketitle

\begin{frame}{Table of contents}
  \setbeamertemplate{section in toc}[sections numbered]
  \tableofcontents[hideallsubsections]
\end{frame}

\section{Introduction}

\begin{frame}[fragile]{What's an Adversarial Example?}

	Machine learning models that misclassify examples that are slightly different(sometimes even imperceptible from human eye) from correctly classified examples drawn from the data distribution.

\end{frame}

\begin{frame}{Problem Definition}
	\begin{exampleblock}{Regular Neural Network Training}
	Train a model on a dataset such that you take the gradient of loss function w.r.t model parameters. In this way, you maximize on the score of the correct class.	
	\end{exampleblock}
	\pause
	\begin{alertblock}{Adversarial Learning}
	Generate an image by doing the following: 
	\pause
	\begin{itemize}
		\item Wiggle the pixel of an image in the direction of the loss function w.r.t to a class different from the target class.This perturbs the image by a tiny bit but the score of the target class is reduced. 
	\end{itemize}  
	Run the model on the generated image and see the classification result. 
	\begin{figure}
		\includegraphics[width=0.5\textwidth]{trump-adv}
	\end{figure}
	\end{alertblock}

\end{frame}
\section{Adversarial Image Generation}
\begin{frame}{Adversarial Example}
	\begin{figure}
		\includegraphics[width=0.5\textwidth]{panda-break}
	\end{figure}

\begin{itemize}
	\item Digital images often use only 8 bits per pixel so they discard all information below $\frac{1}{255}$ of the dynamic range.
	\item The classifier does not respond differently to an input $x$ than to an adversarial input( $\tilde{x} = x + \eta$ ) if every element of the perturbation is smaller than the precision of the features( $\|\eta \|_{\infty} = \epsilon$). 
	\item But then this perturbation causes the activation to grow by $\epsilon m n$ times where $m$ and $n$ are dimensions of weight matrix.
		
\end{itemize}
\end{frame}

\begin{frame}{Neural Networks are linear too!}
\metroset{block=fill}
	\begin{alertblock}{Fooling CNNs}
	\begin{itemize}[<+- | alert@+>]
		\item Deep learning models are meant to express complex non-linear functions.
		\item \alert{\textbf{how are these linear perturbations very effective??}}
	\end{itemize}
	\end{alertblock}

\end{frame}

\begin{frame}{Fast Gradient Sign Method(FGSM)}
\metroset{block=fill}
\begin{itemize}
	
	\item[] { \begin{block}{Model Definition}
		Let $\theta$ be model parameters, $x$ be the input to the model and let $y$ be the target associated with $x$ then the loss for the model would be defined by $L(\theta,x,y)$ .
	\end{block} }
	\pause
	\item[] {We can obtain an adversarial example by having a perturbation in the following manner.  \\
				\begin{equation}
					\eta = \epsilon sign(\nabla_{x} L(\theta, x,y)) 
				\end{equation} 
			
		}
	\pause
	\item[] An Adversarial example($\tilde{x}$) is given by : $\tilde{x} = x + \eta$.  
	\pause
	\item[] Such calculated perturbations make the model confuse over what class to predict.
		
	\item[] {
		\begin{alertblock}{Question:}
			\textbf{\alert{How do we solve this problem?}}
		\end{alertblock}
		
	}

\end{itemize}

\end{frame}

\section{Adversarial Image Training   (White Box Attacks)}
\begin{frame}{Possible Approaches}
	\begin{itemize}
		\item[] {
			\begin{block}{Initial Approach}
				Add the adversarial examples  into the training data. Not super effective, gets the same performance as dropout.
			\end{block}
		}
		\pause
		\item[] {
			\begin{block}{FGSM as Regularizer}
				This method was proved effective with an increased model capacity. Works because such a setting continuously updates adversarial examples.
				The adversarial function would look like: 
			\end{block}
		}
	\pause
		\item[] {
			\begin{equation}\label{fgsm}
				\tilde{L}(\theta,x,y) = \alpha L(\theta,x,y) + (1-\alpha)L(\theta,x + \epsilon sign(\nabla_{x} L(\theta, x,y)))
			\end{equation}
		}
	\pause
	\metroset{block=fill}
	\item[] {
		\begin{alertblock}{When does such a training fail?}
			\begin{itemize}
				\item Label leak problem.
				\item As its a one step process, the adversarial transformation is simple and gets recognized by the model.
			\end{itemize}
			
		\end{alertblock}
	}
\end{itemize}
\end{frame}
\section{Adversarial Image Generation (revisited)}
\begin{frame}{Extensions to FGSM}
\begin{itemize}
	\item[] {
		\begin{block}{Iterative Methods}
		Perform the adversarial image generation $n$ times but clip the perturbation of $\tilde{x}$ to be within the range of $\epsilon$.
		\end{block}
	}
	\pause
	\item[] {
		\begin{block}{More efficient attack}
			Differentiate w.r.t $x$ such that its ground truth is different from $y$.
		\end{block}
	}
	\pause
	\item[] {
		\begin{block}{Adversarial learning for such attacks}
			Incorporating the above mentioned ideas in Eq (\ref{fgsm}) makes the model robust.
		\end{block}
	}
	\pause
	\metroset{block=fill}
	\item[] {
		\begin{exampleblock}{Can we build a completely robust network now?}
			\pause
			\item[] \alert{\textbf{No!}}
		\end{exampleblock}
		
	}
	
\end{itemize}
\end{frame}
\begin{frame}{Extensions to FGSM}
\metroset{block=fill}
\pause
\begin{itemize}
\item[] {
	\begin{alertblock}{Why not??}
		\pause
		\item[] How do you defend against attacks that does not have access to the network (black box attacks) ?!?!
	\end{alertblock}
}
\pause
\item[] {
	\begin{alertblock}{More importantly, do such attacks exists?}
		\pause
		Yes, as its been proven that adversarial examples can transfer between models.
	\end{alertblock}
}
	\end{itemize}
\end{frame}

\section{Adversarial Image Training   (Black Box Attacks)}
\begin{frame}{Black box attacks}
	\metroset{block=fill}
	\begin{block}{Problem Definition}
		Lets assume one is able to generate adversarial images based on the above mentioned generation techniques with different models on a given data distribution or dataset $\textit{D}$. How do we build models robust to such examples? 
	\end{block}
	
\end{frame}
\begin{frame}{Possible Approaches}
\begin{itemize}
	\item[] {
		\begin{block}{Min-Max approach}
			
			\begin{equation}\label{madry-approach}
				h^* = \argmin_{h \in H} E_{(x,y) \sim D}[ \argmax_{\|\tilde{x} - x\|_{\infty} \leq \epsilon} L(H(\tilde{x}),y)]  
			\end{equation}
			This is an universal optimization approach where we minimize the loss function at the same time maximize the adversarial learning.
		\end{block}
	}
	\item[] {
		\begin{block}{Ensemble Adversarial Learning}
			Decouple the adversarial image generation process from learning. Generate adversarial examples from a set of static pre-trained models. Augment them with the real data during training.
		\end{block}
	}
\end{itemize}
		
	
\end{frame}

\section{Applications}
\begin{frame}
	\begin{itemize}
		\item Active learning. it can be seen as model able to request labels on new points.
	\end{itemize}
\end{frame}

\section{Titleformats}

\begin{frame}{Metropolis titleformats}
	\themename supports 4 different titleformats:
	\begin{itemize}
		\item Regular
		\item \textsc{Smallcaps}
		\item \textsc{allsmallcaps}
		\item ALLCAPS
	\end{itemize}
	They can either be set at once for every title type or individually.
	
\end{frame}

{
    \metroset{titleformat frame=smallcaps}
\begin{frame}{Small caps}
	This frame uses the \texttt{smallcaps} titleformat.

	\begin{alertblock}{Potential Problems}
		Be aware, that not every font supports small caps. If for example you typeset your presentation with pdfTeX and the Computer Modern Sans Serif font, every text in smallcaps will be typeset with the Computer Modern Serif font instead.
	\end{alertblock}
\end{frame}
}

{
\metroset{titleformat frame=allsmallcaps}
\begin{frame}{All small caps}
	This frame uses the \texttt{allsmallcaps} titleformat.

	\begin{alertblock}{Potential problems}
		As this titleformat also uses smallcaps you face the same problems as with the \texttt{smallcaps} titleformat. Additionally this format can cause some other problems. Please refer to the documentation if you consider using it.

		As a rule of thumb: Just use it for plaintext-only titles.
	\end{alertblock}
\end{frame}
}

{
\metroset{titleformat frame=allcaps}
\begin{frame}{All caps}
	This frame uses the \texttt{allcaps} titleformat.

	\begin{alertblock}{Potential Problems}
		This titleformat is not as problematic as the \texttt{allsmallcaps} format, but basically suffers from the same deficiencies. So please have a look at the documentation if you want to use it.
	\end{alertblock}
\end{frame}
}

\section{Elements}

\begin{frame}[fragile]{Typography}
      \begin{verbatim}The theme provides sensible defaults to
\emph{emphasize} text, \alert{accent} parts
or show \textbf{bold} results.\end{verbatim}

  \begin{center}becomes\end{center}

  The theme provides sensible defaults to \emph{emphasize} text,
  \alert{accent} parts or show \textbf{bold} results.
\end{frame}

\begin{frame}{Font feature test}
  \begin{itemize}
    \item Regular
    \item \textit{Italic}
    \item \textsc{SmallCaps}
    \item \textbf{Bold}
    \item \textbf{\textit{Bold Italic}}
    \item \textbf{\textsc{Bold SmallCaps}}
    \item \texttt{Monospace}
    \item \texttt{\textit{Monospace Italic}}
    \item \texttt{\textbf{Monospace Bold}}
    \item \texttt{\textbf{\textit{Monospace Bold Italic}}}
  \end{itemize}
\end{frame}

\begin{frame}{Lists}
  \begin{columns}[T,onlytextwidth]
    \column{0.33\textwidth}
      Items
      \begin{itemize}
        \item Milk \item Eggs \item Potatos
      \end{itemize}

    \column{0.33\textwidth}
      Enumerations
      \begin{enumerate}
        \item First, \item Second and \item Last.
      \end{enumerate}

    \column{0.33\textwidth}
      Descriptions
      \begin{description}
        \item[PowerPoint] Meeh. \item[Beamer] Yeeeha.
      \end{description}
  \end{columns}
\end{frame}
\begin{frame}{Animation}
  \begin{itemize}[<+- | alert@+>]
    \item \alert<4>{This is\only<4>{ really} important}
    \item Now this
    \item And now this
  \end{itemize}
\end{frame}
\begin{frame}{Figures}
  \begin{figure}
    \newcounter{density}
    \setcounter{density}{20}
    \begin{tikzpicture}
      \def\couleur{alerted text.fg}
      \path[coordinate] (0,0)  coordinate(A)
                  ++( 90:5cm) coordinate(B)
                  ++(0:5cm) coordinate(C)
                  ++(-90:5cm) coordinate(D);
      \draw[fill=\couleur!\thedensity] (A) -- (B) -- (C) --(D) -- cycle;
      \foreach \x in {1,...,40}{%
          \pgfmathsetcounter{density}{\thedensity+20}
          \setcounter{density}{\thedensity}
          \path[coordinate] coordinate(X) at (A){};
          \path[coordinate] (A) -- (B) coordinate[pos=.10](A)
                              -- (C) coordinate[pos=.10](B)
                              -- (D) coordinate[pos=.10](C)
                              -- (X) coordinate[pos=.10](D);
          \draw[fill=\couleur!\thedensity] (A)--(B)--(C)-- (D) -- cycle;
      }
    \end{tikzpicture}
    \caption{Rotated square from
    \href{http://www.texample.net/tikz/examples/rotated-polygons/}{texample.net}.}
  \end{figure}
\end{frame}
\begin{frame}{Tables}
  \begin{table}
    \caption{Largest cities in the world (source: Wikipedia)}
    \begin{tabular}{lr}
      \toprule
      City & Population\\
      \midrule
      Mexico City & 20,116,842\\
      Shanghai & 19,210,000\\
      Peking & 15,796,450\\
      Istanbul & 14,160,467\\
      \bottomrule
    \end{tabular}
  \end{table}
\end{frame}
\begin{frame}{Blocks}
  Three different block environments are pre-defined and may be styled with an
  optional background color.

  \begin{columns}[T,onlytextwidth]
    \column{0.5\textwidth}
      \begin{block}{Default}
        Block content.
      \end{block}

      \begin{alertblock}{Alert}
        Block content.
      \end{alertblock}

      \begin{exampleblock}{Example}
        Block content.
      \end{exampleblock}

    \column{0.5\textwidth}

      \metroset{block=fill}

      \begin{block}{Default}
        Block content.
      \end{block}

      \begin{alertblock}{Alert}
        Block content.
      \end{alertblock}

      \begin{exampleblock}{Example}
        Block content.
      \end{exampleblock}

  \end{columns}
\end{frame}
\begin{frame}{Math}
  \begin{equation*}
    e = \lim_{n\to \infty} \left(1 + \frac{1}{n}\right)^n
  \end{equation*}
\end{frame}
\begin{frame}{Line plots}
  \begin{figure}
    \begin{tikzpicture}
      \begin{axis}[
        mlineplot,
        width=0.9\textwidth,
        height=6cm,
      ]

        \addplot {sin(deg(x))};
        \addplot+[samples=100] {sin(deg(2*x))};

      \end{axis}
    \end{tikzpicture}
  \end{figure}
\end{frame}
\begin{frame}{Bar charts}
  \begin{figure}
    \begin{tikzpicture}
      \begin{axis}[
        mbarplot,
        xlabel={Foo},
        ylabel={Bar},
        width=0.9\textwidth,
        height=6cm,
      ]

      \addplot plot coordinates {(1, 20) (2, 25) (3, 22.4) (4, 12.4)};
      \addplot plot coordinates {(1, 18) (2, 24) (3, 23.5) (4, 13.2)};
      \addplot plot coordinates {(1, 10) (2, 19) (3, 25) (4, 15.2)};

      \legend{lorem, ipsum, dolor}

      \end{axis}
    \end{tikzpicture}
  \end{figure}
\end{frame}
\begin{frame}{Quotes}
  \begin{quote}
    Veni, Vidi, Vici
  \end{quote}
\end{frame}

{%
\setbeamertemplate{frame footer}{My custom footer}
\begin{frame}[fragile]{Frame footer}
    \themename defines a custom beamer template to add a text to the footer. It can be set via
    \begin{verbatim}\setbeamertemplate{frame footer}{My custom footer}\end{verbatim}
\end{frame}
}

\begin{frame}{References}
  Some references to showcase [allowframebreaks] \cite{knuth92,ConcreteMath,Simpson,Er01,greenwade93}
\end{frame}

\section{Conclusion}

\begin{frame}{Summary}

  Get the source of this theme and the demo presentation from

  \begin{center}\url{github.com/matze/mtheme}\end{center}

  The theme \emph{itself} is licensed under a
  \href{http://creativecommons.org/licenses/by-sa/4.0/}{Creative Commons
  Attribution-ShareAlike 4.0 International License}.

  \begin{center}\ccbysa\end{center}

\end{frame}

{\setbeamercolor{palette primary}{fg=black, bg=yellow}
\begin{frame}[standout]
  Questions?
\end{frame}
}

\appendix

\begin{frame}[fragile]{Backup slides}
  Sometimes, it is useful to add slides at the end of your presentation to
  refer to during audience questions.

  The best way to do this is to include the \verb|appendixnumberbeamer|
  package in your preamble and call \verb|\appendix| before your backup slides.

  \themename will automatically turn off slide numbering and progress bars for
  slides in the appendix.
\end{frame}

\begin{frame}[allowframebreaks]{References}

  \bibliography{demo}
  \bibliographystyle{abbrv}

\end{frame}

\end{document}
